{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sugarcrepe benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# get dataset\n",
    "dest = \"val2017\"\n",
    "url = \"http://images.cocodataset.org/zips/val2017.zip\"\n",
    "!wget $url\n",
    "!unzip -q val2017.zip -d $dest\n",
    "!rm val2017.zip"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# get labels\n",
    "!mkdir labels\n",
    "for name in [\"add_att\", \"add_obj\",\"replace_att\", \"replace_obj\", \"replace_rel\", \"swap_att\", \"swap_obj\"]:\n",
    "    !wget https://raw.githubusercontent.com/RAIVNLab/sugar-crepe/main/data/{name}.json -O labels/{name}.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import optax\n",
    "import orbax\n",
    "import wandb\n",
    "from flax.training import orbax_utils\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from clip_jax import CLIPModel\n",
    "from clip_jax.data import image_to_logits, shift_tokens_left\n",
    "from clip_jax.tokenizer import AutoTokenizer\n",
    "from clip_jax.utils import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert jax.local_device_count() > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_name = \"cappa_tokenizer\"\n",
    "model_checkpoint = \"craiyon/cappa-jax/config-ydqtfo4c:latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CLIPModel(**config)\n",
    "rng = jax.random.PRNGKey(0)\n",
    "logical_shape = jax.eval_shape(lambda rng: model.init_weights(rng), rng)[\"params\"]\n",
    "params = jax.tree.map(lambda x: jnp.zeros(x.shape, dtype=x.dtype), logical_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact = wandb.Api().artifact(model_checkpoint)\n",
    "model_path = artifact.metadata[\"output_dir\"]\n",
    "step = int(artifact.metadata[\"step\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore checkpoint\n",
    "ckpt = {\"params\": params}\n",
    "restore_args = orbax_utils.restore_args_from_target(ckpt)\n",
    "orbax_checkpointer = orbax.checkpoint.PyTreeCheckpointer()\n",
    "orbax_options = orbax.checkpoint.CheckpointManagerOptions()\n",
    "checkpoint_manager = orbax.checkpoint.CheckpointManager(model_path, orbax_checkpointer, orbax_options)\n",
    "ckpt = checkpoint_manager.restore(step, ckpt, restore_kwargs={\"restore_args\": restore_args, \"transforms\": {}})\n",
    "params = ckpt[\"params\"]\n",
    "del ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(c):\n",
    "    captions = \" \".join(\n",
    "                c.lower()\n",
    "                .replace(\",\", \", \")\n",
    "                .replace(\".\", \". \")\n",
    "                .replace(\"-\", \" \")\n",
    "                .replace(\";\", \", \")\n",
    "                .replace(\":\", \", \")\n",
    "                .replace('\"', ' \" ')\n",
    "                .replace(\"/\", \", \")\n",
    "                .replace(\".\", \", \")\n",
    "                .replace(\")\", \", \")\n",
    "                .replace(\" (\", \", \")\n",
    "                .strip(\", ?\\n\")\n",
    "                .split()\n",
    "            ).replace(\" ,\", \",\")\n",
    "    txt_inputs = tokenizer(\n",
    "        captions,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=config[\"text_config\"][\"max_length\"],\n",
    "        return_tensors=\"np\",\n",
    "    )\n",
    "    labels = shift_tokens_left(txt_inputs[\"input_ids\"], pad_token_id=tokenizer.pad_token_id)\n",
    "    labels_mask = shift_tokens_left(txt_inputs[\"attention_mask\"], pad_token_id=0)\n",
    "    return {\n",
    "        \"input_ids\": txt_inputs[\"input_ids\"],\n",
    "        \"attention_mask\": txt_inputs[\"attention_mask\"],\n",
    "        \"labels\": labels,\n",
    "        \"labels_mask\": labels_mask,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_item(item):\n",
    "    # image\n",
    "    img = Image.open(f\"val2017/{item['filename']}\")\n",
    "    img = img.resize((256, 256))\n",
    "    img = img.convert(\"RGB\")\n",
    "    pixel_values = image_to_logits(img)\n",
    "    pixel_values = pixel_values[np.newaxis, ...]\n",
    "    # text   \n",
    "    pos_inputs = process_text(item[\"caption\"])\n",
    "    neg_inputs = process_text(item[\"negative_caption\"])\n",
    "    return {\n",
    "        \"pixel_values\": pixel_values,\n",
    "        \"pos_inputs\": pos_inputs,\n",
    "        \"neg_inputs\": neg_inputs,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def get_scores(pixel_values, inputs, params):\n",
    "    assert pixel_values.shape[0] == 1, \"only support 1 image at a time\"\n",
    "    encoder_outputs = model.apply({\"params\": params}, pixel_values=pixel_values, method=model.get_image_features)[\n",
    "        \"vision_model_output\"\n",
    "    ][\"last_hidden_state\"]\n",
    "    logits = model.apply(\n",
    "        {\"params\": params},\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        encoder_hidden_states=encoder_outputs,\n",
    "        decode=False,\n",
    "        method=model.get_text_features,\n",
    "    )[\"text_model_output\"][\"last_hidden_state\"]\n",
    "    score = -optax.softmax_cross_entropy_with_integer_labels(logits, inputs[\"labels\"]) * inputs[\"labels_mask\"]\n",
    "    score = score.sum(axis=-1)\n",
    "    return score[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for benchmark in [\"add_att\", \"add_obj\",\"replace_att\", \"replace_obj\", \"replace_rel\", \"swap_att\", \"swap_obj\"]:\n",
    "    print(f\"benchmark: {benchmark}\")\n",
    "    labels = json.load(open(f\"labels/{benchmark}.json\"))\n",
    "    count = 0\n",
    "    success = 0\n",
    "    for item in tqdm(labels.values()):\n",
    "        inputs = load_item(item)\n",
    "        pos_score = get_scores(inputs[\"pixel_values\"], inputs[\"pos_inputs\"], params)\n",
    "        neg_score = get_scores(inputs[\"pixel_values\"], inputs[\"neg_inputs\"], params)\n",
    "        count += 1\n",
    "        if pos_score > neg_score:\n",
    "            success += 1\n",
    "    print(f\"count: {count}, success: {success}, acc: {success / count}\")\n",
    "    results[benchmark] = success / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
