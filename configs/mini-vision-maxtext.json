{
  "text_config": {
    "decoder_block": "mistral",
    "num_experts": 1,
    "vocab_size": 32000,
    "emb_dim": 256,
    "mlp_dim": 512,
    "num_decoder_layers": 5,
    "num_query_heads": 8,
    "normalization_layer_epsilon": 1e-05,
    "head_dim": 32,
    "num_kv_heads": 8,
    "mlp_activations": [
      "silu",
      "linear"
    ],
    "logits_dot_in_fp32": true,
    "use_iota_embed": false,
    "use_untrainable_positional_embedding": false,
    "trainable_position_size": -1,
    "enable_dropout": false,
    "dropout_rate": 0,
    "scan_layers": true,
    "attention": "dot_product",
    "quantize_kvcache": false,
    "fused_qkv": false,
    "fused_mlp": false,
    "record_internal_nn_metrics": 0,
    "logits_via_embedding": false,
    "param_scan_axis": 1,
    "weight_dtype": "float32",
    "pad_token_id": null,
    "eos_token_id": 2,
    "remat_policy": "none",
    "activation_partitioning_dims": 2,
    "parameter_partitioning_dims": 2,
    "mp_devices": 8,
    "max_target_length": 512,
    "max_prefill_predict_length": 384,
    "dtype": "float32"
  },
  "vision_config": {
    "float32_logits": true,
    "position_embedding_type": "learnt",
    "position_embedding_shape": null,
    "position_embedding_factorized": false,
    "dtype": "float32",
    "activations": [
      "gelu",
      "linear"
    ],
    "normalize_qk": false,
    "use_bias": false,
    "force_scale": false,
    "attention_dropout": 0.0,
    "mlp_dropout_rate": 0.0,
    "pool_type": null,
    "unroll": 100,
    "registers": 8,
    "keep_registers": true,
    "remat_policy": "none",
    "num_queries": 1,
    "image_size": 256,
    "hidden_size": 256,
    "patch_size": 16,
    "num_layers": 5,
    "use_rmsnorm": true,
    "ln_type": "normformer",
    "num_heads": 8,
    "use_causal_mask": false,
    "mlp_dim": 512
  },
  "projection_dim": 1024,
  "logit_scale_init_value": 2.3,
  "logit_bias_init_value": -10.0,
  "dtype": "float32"
}